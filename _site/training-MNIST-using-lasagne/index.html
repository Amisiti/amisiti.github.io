<!DOCTYPE html>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Training MNIST Neural Networks Using Lasagne</title>
	<meta name="viewport" content="width=device-width">
	<meta name="description" content="Joe is a software engineer living in lower manhattan that specializes in machine learning, statistics, python, and computer vision.">
	<link rel="canonical" href="/training-MNIST-using-lasagne">
	
	<link href='//fonts.googleapis.com/css?family=Titillium+Web:400,200|Lato:300,400,700|Pacifico' rel='stylesheet' type='text/css' />
	
	<!-- Custom CSS -->
	<link rel="stylesheet" href="/css/main.css">
	<link rel="stylesheet" href="/css/icons.css">
	<script type="text/javascript"
	    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
        
    <!-- start Mixpanel --><script type="text/javascript">(function(e,b){if(!b.__SV){var a,f,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable time_event track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.union people.track_charge people.clear_charges people.delete_user".split(" ");
    for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=e.createElement("script");a.type="text/javascript";a.async=!0;a.src="undefined"!==typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:"file:"===e.location.protocol&&"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//)?"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js":"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js";f=e.getElementsByTagName("script")[0];f.parentNode.insertBefore(a,f)}})(document,window.mixpanel||[]);
    mixpanel.init("4a9ea1c313c2d3a01e19ad4f9558dba4");</script><!-- end Mixpanel -->
</head>

	
	<body>
		<header class="site-header">
	<div class="wrap">
		<a class="site-title" href="/">
		</a>
		<nav class="site-nav">
			<div class="trigger">
			</div>
		</nav>
	</div>
</header>
		
		<div class="page-content">
			<div class="wrap">
				<div class="post" style="padding:1.85em 0.75em;">
	<a class="home-link" href="/">Back To Blog Posts</a>
    <header class="post-header">
		<p class="meta">Oct 5, 2015
            </p>
		
		<h1>Training MNIST Neural Networks Using Lasagne</h1>
	</header>
	
	<article class="post-content">
		<p>The past few weeks, I have been experimenting with the latest-and-greatest deep learning networks, all written in <code>python</code>, to decide which framework I could dive into an become an expert in. After looking at <a href="">hebel</a>, <a href="">keras</a>, <a href="">chainer</a>, and <a href="">Lasagne</a>, I decided to go with Lasagne because of the documentation and tutorials available online. The other frameworks are great, it just seemed like Lasagne currently has the most tutorials and the best docs.</p>

<p>In this blog post, I am going to show you how to use the Lasagne framework to train a neural network on the MNIST database. In later blog posts, I am going to use Lasagne to solve a variety of deep learning problems in natural language processing and computer vision.</p>

<p>All of my work was done on an GPU <code>g2.8xlarge</code> rented on Amazon AWS. Specifically, I was able to utilize the following AMI to do this work: <code>ami-55deaf30</code>.</p>

<p>To start with, I need to load the MNIST database into a format that <code>Lasagne</code> accepts, which happens to be <code>numpy</code> matrices. Luckily, I did not need tow write much code here because <a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_loader.py">mnielsen</a> did most of the work for me. I did end up writing a single method that utilized his code:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">testing</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>   
        <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_results</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span></code></pre></div>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c">#### Libraries</span>
<span class="c"># Standard library</span>
<span class="kn">import</span> <span class="nn">cPickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;./data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">testing</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">testing</span><span class="p">:</span>   
        <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_results</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span>
    
<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span></code></pre></div>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">lasagne</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">;</span>
<span class="kn">from</span> <span class="nn">lasagne.updates</span> <span class="kn">import</span> <span class="n">nesterov_momentum</span><span class="p">;</span>
<span class="kn">from</span> <span class="nn">nolearn.lasagne</span> <span class="kn">import</span> <span class="n">NeuralNet</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="p">;</span>

<span class="n">net1</span> <span class="o">=</span> <span class="n">NeuralNet</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">=</span><span class="p">[</span>  <span class="c"># three layers: one hidden layer</span>
        <span class="p">(</span><span class="s">&#39;input&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;hidden&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;output&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">),</span>
        <span class="p">],</span>
    <span class="c"># layer parameters:</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span>  <span class="c"># 96x96 input pixels per batch</span>
    <span class="n">hidden_num_units</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>  <span class="c"># number of units in hidden layer</span>
    <span class="n">output_nonlinearity</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>  <span class="c"># output layer uses identity function</span>
    <span class="n">output_num_units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c"># 30 target values</span>

    <span class="c"># optimization method:</span>
    <span class="n">update</span><span class="o">=</span><span class="n">nesterov_momentum</span><span class="p">,</span>
    <span class="n">update_learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">update_momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>

    <span class="n">regression</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c"># flag to indicate we&#39;re dealing with regression problem</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span>  <span class="c"># we want to train this many epochs</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    
  
<span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">load</span><span class="p">()</span>  
<span class="n">net1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></div>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Neural Network with 79510 learnable parameters</span>

<span class="c">## Layer information</span>

  <span class="c">#  name      size</span>
<span class="o">---</span>  <span class="o">------</span>  <span class="o">------</span>
  <span class="mi">0</span>  <span class="nb">input</span>      <span class="mi">784</span>
  <span class="mi">1</span>  <span class="n">hidden</span>     <span class="mi">100</span>
  <span class="mi">2</span>  <span class="n">output</span>      <span class="mi">10</span>

  <span class="n">epoch</span>    <span class="n">train</span> <span class="n">loss</span>    <span class="n">valid</span> <span class="n">loss</span>    <span class="n">train</span><span class="o">/</span><span class="n">val</span>  <span class="n">dur</span>
<span class="o">-------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">-----------</span>  <span class="o">-----</span>
      <span class="mi">1</span>       <span class="mf">0.06673</span>       <span class="mf">0.04498</span>      <span class="mf">1.48367</span>  <span class="mf">0.48</span><span class="n">s</span>
      <span class="mi">2</span>       <span class="mf">0.04156</span>       <span class="mf">0.03616</span>      <span class="mf">1.14935</span>  <span class="mf">0.41</span><span class="n">s</span>
      <span class="mi">3</span>       <span class="mf">0.03523</span>       <span class="mf">0.03184</span>      <span class="mf">1.10660</span>  <span class="mf">0.41</span><span class="n">s</span>
      <span class="mi">4</span>       <span class="mf">0.03165</span>       <span class="mf">0.02910</span>      <span class="mf">1.08774</span>  <span class="mf">0.41</span><span class="n">s</span>
      <span class="mi">5</span>       <span class="mf">0.02921</span>       <span class="mf">0.02713</span>      <span class="mf">1.07678</span>  <span class="mf">0.43</span><span class="n">s</span>
      <span class="mi">6</span>       <span class="mf">0.02738</span>       <span class="mf">0.02560</span>      <span class="mf">1.06937</span>  <span class="mf">0.44</span><span class="n">s</span>
      <span class="mi">7</span>       <span class="mf">0.02593</span>       <span class="mf">0.02437</span>      <span class="mf">1.06394</span>  <span class="mf">0.44</span><span class="n">s</span>
      <span class="mi">8</span>       <span class="mf">0.02475</span>       <span class="mf">0.02336</span>      <span class="mf">1.05926</span>  <span class="mf">0.44</span><span class="n">s</span>
      <span class="mi">9</span>       <span class="mf">0.02376</span>       <span class="mf">0.02251</span>      <span class="mf">1.05548</span>  <span class="mf">0.42</span><span class="n">s</span>
     <span class="mi">10</span>       <span class="mf">0.02293</span>       <span class="mf">0.02179</span>      <span class="mf">1.05204</span>  <span class="mf">0.42</span><span class="n">s</span>
     
     <span class="o">......</span>

    <span class="mi">391</span>       <span class="mf">0.00703</span>       <span class="mf">0.00939</span>      <span class="mf">0.74809</span>  <span class="mf">0.44</span><span class="n">s</span>
    <span class="mi">392</span>       <span class="mf">0.00702</span>       <span class="mf">0.00939</span>      <span class="mf">0.74772</span>  <span class="mf">0.41</span><span class="n">s</span>
    <span class="mi">393</span>       <span class="mf">0.00702</span>       <span class="mf">0.00939</span>      <span class="mf">0.74724</span>  <span class="mf">0.42</span><span class="n">s</span>
    <span class="mi">394</span>       <span class="mf">0.00701</span>       <span class="mf">0.00939</span>      <span class="mf">0.74683</span>  <span class="mf">0.43</span><span class="n">s</span>
    <span class="mi">395</span>       <span class="mf">0.00700</span>       <span class="mf">0.00938</span>      <span class="mf">0.74634</span>  <span class="mf">0.42</span><span class="n">s</span>
    <span class="mi">396</span>       <span class="mf">0.00700</span>       <span class="mf">0.00938</span>      <span class="mf">0.74590</span>  <span class="mf">0.42</span><span class="n">s</span>
    <span class="mi">397</span>       <span class="mf">0.00699</span>       <span class="mf">0.00938</span>      <span class="mf">0.74554</span>  <span class="mf">0.43</span><span class="n">s</span>
    <span class="mi">398</span>       <span class="mf">0.00699</span>       <span class="mf">0.00938</span>      <span class="mf">0.74508</span>  <span class="mf">0.45</span><span class="n">s</span>
    <span class="mi">399</span>       <span class="mf">0.00698</span>       <span class="mf">0.00938</span>      <span class="mf">0.74453</span>  <span class="mf">0.43</span><span class="n">s</span>
    <span class="mi">400</span>       <span class="mf">0.00698</span>       <span class="mf">0.00937</span>      <span class="mf">0.74412</span>  <span class="mf">0.41</span><span class="n">s</span></code></pre></div>

<p>TODO - add evaluation stuff here …</p>

	</article>
    
    <script>
        mixpanel.track("Training MNIST Neural Networks Using Lasagne");
    </script>
    
</div>
			</div>
		</div>
		<footer class="site-footer">
	<div class="wrap">
		<div class="footer-col-1 column">
			<ul>
				<li>Math, CS, Statsitics, and the occasional book review</li>
				<li>
					<a href="mailto:"></a>
				</li>
			</ul>
		</div>
		
		<div class="footer-col-2 column">
			<ul>
				<li>
					<a class="icons icon-signup" href="/feed.xml"></a>
				</li>
				
				<li>
					<a class="icons icon-github2" href="https://github.com/">
						<span class="username"></span>
					</a>
				</li>
				
				<li>
					<a class="icons icon-twitter" href="https://twitter.com/">
						<span class="username"></span>
					</a>
				</li>
			</ul>
		</div>
		
		<div class="footer-col-3 column">
			<p class="text">Joe is a software engineer living in lower manhattan that specializes in machine learning, statistics, python, and computer vision.</p>
		</div>
	</div>
</footer>
	</body>
</html>